{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from project.data.preprocessed.unsplit import unsplit_data as UNSPLIT\n",
    "from project.data.preprocessed.split import split_data as SPLIT\n",
    "from project.utils.tokenize import nltk_tok\n",
    "\n",
    "TOTAL = []\n",
    "TOTAL.extend(UNSPLIT.train)\n",
    "TOTAL.extend(UNSPLIT.valid)\n",
    "# TOTAL.extend(UNSPLIT.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_and_bottom(counter_obj, count, name, cols=2, width=35):\n",
    "    mc = counter_obj.most_common()\n",
    "    top_x = mc[:count]\n",
    "    bottom_x = mc[-count:]\n",
    "    \n",
    "    top = \"\\n\".join(\"{}. {}\".format(i+1, x) for i,x in enumerate(top_x))\n",
    "    bottom = \"\\n\".join(\"{}. {}\".format(i+1, x) for i,x in enumerate(reversed(bottom_x)))\n",
    "    \n",
    "    s = '''TOP {count} {name}\\n{top}\\nBOTTOM {count} {name}\\n{bottom}'''.format(\n",
    "        count=count, name=name, top=top, bottom=bottom\n",
    "    )\n",
    "    print(to_columns(s, cols, width))\n",
    "    return mc\n",
    "\n",
    "def to_columns(string, cols, width):\n",
    "    lines = string.split(\"\\n\")\n",
    "    lpc = int(len(lines) / cols)\n",
    "    columns = [lines[i*lpc:(i+1)*lpc] for i in range(cols)]\n",
    "    \n",
    "    max_c = max([len(c) for c in columns])\n",
    "    for c in columns:\n",
    "        size = len(c)\n",
    "        for i in range(max_c - size):\n",
    "            c.append(\" \")\n",
    "    \n",
    "    final_text = []\n",
    "    for i in range(len(lines)):\n",
    "        final_text.append(str.ljust(columns[i % cols][(i // cols)], width, \" \"))\n",
    "        if i % cols == cols-1:\n",
    "            final_text.append('\\n')\n",
    "    return \"\".join(final_text)\n",
    "\n",
    "def get_histogram(counter, bins, name):\n",
    "    counts = [n[1] for n in counter]\n",
    "    total = sum(counts)\n",
    "    args = len(counter)\n",
    "    meta_counter = Counter(counts)\n",
    "    \n",
    "    h = np.histogram(counts, bins)\n",
    "\n",
    "    lines = [ \n",
    "        \"Histogram: {}\".format(name),\n",
    "        \"\\n\",\n",
    "        str.ljust(\"Bin\", 10, \" \"),\n",
    "        str.rjust(\"Count\", 7, \" \"),\n",
    "        str.rjust(\"% of names\", 12, \" \"),\n",
    "        str.rjust(\"% of vars\", 10, \" \"), \n",
    "        str.rjust(\"%-ile vars \", 13, \" \"), \n",
    "        \"\\n\",\n",
    "    ]\n",
    "    \n",
    "    cumulative = 0 \n",
    "    for i in range(1, len(h[1])-1):\n",
    "        bucket_min, bucket_max = h[1][i], h[1][i+1] \n",
    "        lines.append(str.ljust(\"{}-{}\".format(bucket_min, bucket_max), 10, \" \"))\n",
    "        lines.append(str.rjust(\"{}\".format(h[0][i]), 7, \" \"))\n",
    "        lines.append(str.rjust(\"{:.3f}\".format(100*h[0][i]/args), 11, \" \"))\n",
    "        \n",
    "        tot = 0\n",
    "        for i in range(bucket_min, bucket_max):\n",
    "            if i in meta_counter:\n",
    "                tot += i * meta_counter[i]\n",
    "        lines.append(str.rjust(\"{:.3f}\".format(100*tot/total), 11, \" \"))\n",
    "        cumulative += 100*tot/total\n",
    "        lines.append(str.rjust(\"{:.2f}\".format(cumulative), 11, \" \"))\n",
    "        \n",
    "        lines.append(\"\\n\")\n",
    "    return \"\".join(lines)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 Argument Names              BOTTOM 10 Argument Names           \n",
      "1. ('name', 1913)                  1. ('gamma_max', 1)                \n",
      "2. ('x', 443)                      2. ('num_resampled', 1)            \n",
      "3. ('kwargs', 309)                 3. ('namespace', 1)                \n",
      "4. ('axis', 251)                   4. ('make_keys_unique_seed', 1)    \n",
      "5. ('dtype', 250)                  5. ('compute_full_tree', 1)        \n",
      "6. ('input', 247)                  6. ('allow_extra_args', 1)         \n",
      "7. ('a', 234)                      7. ('reverse_vi_search_direction', 1)\n",
      "8. ('G', 216)                      8. ('new_row_vocab_size', 1)       \n",
      "9. ('value', 212)                  9. ('embedding_variable', 1)       \n",
      "10. ('inputs', 209)                10. ('backward_command', 1)        \n",
      "\n",
      "TOP 10 Function Names              BOTTOM 10 Function Names           \n",
      "1. ('fit', 114)                    1. ('rruleset', 1)                 \n",
      "2. ('transform', 107)              2. ('CoopTestCase', 1)             \n",
      "3. ('evaluate', 79)                3. ('automatic_control_dependencies', 1)\n",
      "4. ('train', 70)                   4. ('square_clustering', 1)        \n",
      "5. ('get', 62)                     5. ('loss_only_head', 1)           \n",
      "6. ('conv2d', 58)                  6. ('append_flags_into_file', 1)   \n",
      "7. ('Client', 50)                  7. ('cookie_date', 1)              \n",
      "8. ('boxplot', 49)                 8. ('prefer_static_rank', 1)       \n",
      "9. ('batch_normalization', 42)     9. ('separate_stains', 1)          \n",
      "10. ('update', 42)                 10. ('wantMethod', 1)              \n",
      "\n",
      "Histogram: Arg Names                                        Histogram: Func Names                                       \n",
      "Bin         Count  % of names % of vars  %-ile vars         Bin         Count  % of names % of vars  %-ile vars         \n",
      "1-2          3661     53.949     11.820      11.82          1-2          2449     28.965      7.907       7.91          \n",
      "2-3          1253     18.464      8.091      19.91          2-3          1871     22.129     12.082      19.99          \n",
      "3-4           527      7.766      5.105      25.02          3-4          1206     14.264     11.682      31.67          \n",
      "4-5           315      4.642      4.068      29.08          4-5           849     10.041     10.965      42.64          \n",
      "5-10          529      7.795     11.146      40.23          5-10         1623     19.196     32.907      75.54          \n",
      "10-20         267      3.935     11.352      51.58          10-20         360      4.258     14.678      90.22          \n",
      "20-50         161      2.373     15.943      67.53          20-50          90      1.064      8.036      98.26          \n",
      "50-100         42      0.619      9.308      76.83          50-100          5      0.059      1.030      99.29          \n",
      "100-200        21      0.309      9.334      86.17          100-200         2      0.024      0.714     100.00          \n",
      "200-500         9      0.133      7.655      93.82          200-500         0      0.000      0.000     100.00          \n",
      "500-3000        1      0.015      6.177     100.00          500-3000        0      0.000      0.000     100.00          \n",
      "                                                                                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 10\n",
    "def counts():\n",
    "    arg_names = Counter(x['arg_name'] for x in TOTAL)\n",
    "    func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "    mc_arg_name = print_top_and_bottom(arg_names, TOP_N, \"Argument Names\")\n",
    "    mc_func_name = print_top_and_bottom(func_names, TOP_N, \"Function Names\")\n",
    "    \n",
    "    name_bins =  [0,1,2,3,4,5,10,20,50,100,200,500,3000]\n",
    "    name_h = get_histogram(mc_arg_name, name_bins, \"Arg Names\")\n",
    "    func_bins =  [0,1,2,3,4,5,10,20,50,100,200]\n",
    "    func_h = get_histogram(mc_func_name, name_bins, \"Func Names\")\n",
    "    print(to_columns(name_h + '\\n' + func_h , 2, 60))\n",
    "\n",
    "        \n",
    "counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Unique [Arg, Desc]\n",
      "\n",
      "N. Count  [Arg, Desc]\n",
      "1  1056   ['name', 'a name for the operation ( optional ) .']\n",
      "\n",
      "2  94     ['timeout', 'the amount of time , in seconds , to wait for the request to complete . note that if `` retry `` is specified , the timeout applies to each individual attempt .']\n",
      "\n",
      "3  92     ['retry', 'a retry object used to retry requests . if `` none `` is specified , requests will not be retried .']\n",
      "\n",
      "4  70     ['name', 'optional op name .']\n",
      "\n",
      "5  66     ['options', 'overrides the default settings for this call , e.g , timeout , retries etc .']\n",
      "\n",
      "6  56     ['G', 'a networkx graph']\n",
      "\n",
      "7  46     ['name', 'an optional variable_scope name .']\n",
      "\n",
      "8  44     ['image', 'input image .']\n",
      "\n",
      "9  42     ['random_state', 'if int , random_state is the seed used by the random number generator ; if randomstate instance , random_state is the random number generator ; if none , the random number generator is the randomstate instance used by ` np.random ` .']\n",
      "\n",
      "10 37     ['name', 'a name for this operation ( optional ) .']\n",
      "\n",
      "11 36     ['x', 'tensor or variable .']\n",
      "\n",
      "12 34     ['node', 'the root of the parse tree that matched the fixer .']\n",
      "\n",
      "13 32     ['container', \"an optional ` string ` . defaults to ` `` '' ` .\"]\n",
      "\n",
      "14 32     ['results', 'a dict mapping symbolic names to part of the match .']\n",
      "\n",
      "15 31     ['name', 'a string , the name of the layer .']\n",
      "\n",
      "16 31     ['output_shapes', 'a list of shapes ( each a ` tf.tensorshape ` or list of ` ints ` ) that has length ` > = 1 ` .']\n",
      "\n",
      "17 30     ['scope', 'the scope for the operations performed in computing the loss .']\n",
      "\n",
      "18 30     ['padding', \"` `` same '' , `` valid '' ` . the type of padding algorithm to use .\"]\n",
      "\n",
      "19 30     ['output_types', 'a list of ` tf.dtypes ` that has length ` > = 1 ` .']\n",
      "\n",
      "20 28     ['use_bias', 'boolean , whether the layer uses a bias .']\n",
      "\n",
      "\n",
      "\n",
      "Histogram: Unique Names + Desc\n",
      "Bin         Count  % of names % of vars  %-ile vars \n",
      "1-2         14772     77.114     47.695      47.69\n",
      "2-3          2655     13.860     17.145      64.84\n",
      "3-4           712      3.717      6.897      71.74\n",
      "4-5           365      1.905      4.714      76.45\n",
      "5-10          468      2.443      9.454      85.90\n",
      "10-20         133      0.694      5.566      91.47\n",
      "20-50          45      0.235      3.900      95.37\n",
      "50-100          5      0.026      1.220      96.59\n",
      "100-200         0      0.000      0.000      96.59\n",
      "200-3000        1      0.005      3.410     100.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 20\n",
    "def check_for_duplicates():\n",
    "    div = \"<!!S!!>\"\n",
    "    arg_names = Counter(x['arg_name'] + div + \" \".join(nltk_tok(x['arg_desc'])) for x in TOTAL)\n",
    "    mc = arg_names.most_common()\n",
    "    print(\"Check for Unique [Arg, Desc]\\n\")\n",
    "    print(\"{}\".format(\"N. Count  [Arg, Desc]\"))\n",
    "    \n",
    "    for i, (arg_desc, c) in enumerate(mc[:TOP_N]):\n",
    "        line = [\n",
    "            str.ljust(\"{}\".format(i+1), 3, \" \"),\n",
    "            str.ljust(\"{}\".format(c), 7, \" \"),\n",
    "            \"{}\".format(arg_desc.split(div)),\n",
    "            \"\\n\"\n",
    "        ]\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "    print()\n",
    "    print()\n",
    "    name_bins =  [0,1,2,3,4,5,10,20,50,100,200,3000]\n",
    "    name_h = get_histogram(mc, name_bins, \"Unique Names + Desc\")\n",
    "    print(name_h)\n",
    "    \n",
    "check_for_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. name   1913 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (1650) tensorflow    |   (1055) a name for the operation (optional).\n",
      "    (54)   google        |   (70)   optional op name.\n",
      "    (45)   tflearn       |   (46)   an optional variable_scope name.\n",
      "    (14)   external      |   (37)   a name for this operation (optional).\n",
      "    (14)   matplotlib    |   (31)   a string, the name of the layer.\n",
      "\n",
      "2. x       443 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (303)  tensorflow    |   (36)   tensor or variable.\n",
      "    (45)   matplotlib    |   (17)   a tensor or variable.\n",
      "    (34)   scipy         |   (13)   numeric `tensor`.\n",
      "    (12)   tflearn       |   (12)   `bfloat16`, `half`, `float32`, `float64`, `complex64`, `com [...]\n",
      "    (10)   dask          |   (9)    `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`,  [...]\n",
      "\n",
      "3. kwargs  309 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (61)   tensorflow    |   (10)   optional arguments that ``request`` takes.\n",
      "    (49)   google        |   (10)   additional properties to be set on the :class:`~.google.clo [...]\n",
      "    (26)   dask          |   (10)   additional keyword arguments which will be passed to the ap [...]\n",
      "    (21)   mir_eval      |   (9)    standard layer keyword arguments.\n",
      "    (17)   librosa       |   (4)    alternative way to pass arguments\n",
      "\n",
      "4. axis    251 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (82)   tensorflow    |   (10)   the dimensions to reduce. if `none` (the default), reduces  [...]\n",
      "    (58)   scipy         |   (10)   axis to broadcast over\n",
      "    (53)   pandas        |   (8)    the axis of `input` along which to calculate. default is -1 [...]\n",
      "    (22)   dask          |   (4)    the dimensions to reduce; list or scalar. if `none` (the de [...]\n",
      "    (15)   librosa       |   (4)    align on index (0), columns (1), or both (none)\n",
      "\n",
      "5. dtype   250 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (152)  tensorflow    |   (11)   a `tf.dtype`.\n",
      "    (36)   scipy         |   (7)    default data type for internal matrices. set to np.float32  [...]\n",
      "    (11)   networkx      |   (6)    the data type. only floating point types are supported.\n",
      "    (8)    sklearn       |   (5)    the type of features. only string and integer types are sup [...]\n",
      "    (8)    tflearn       |   (5)    overrides the data type of the result.\n",
      "\n",
      "6. input   247 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (157)  tensorflow    |   (27)   the input array.\n",
      "    (55)   scipy         |   (22)   a `tensor`.\n",
      "    (23)   torch         |   (8)    input\n",
      "    (3)    seaborn       |   (8)    a `tensor` of type `complex64`. a complex64 tensor.\n",
      "    (3)    webencodings  |   (6)    a `tensor` of type `complex64`.\n",
      "\n",
      "7. a       234 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (98)   scipy         |   (25)   input array.\n",
      "    (72)   tensorflow    |   (10)   input array, can be complex.\n",
      "    (27)   dask          |   (8)    input data.\n",
      "    (23)   numpy         |   (6)    input array\n",
      "    (3)    seaborn       |   (6)    a `tensor`.\n",
      "\n",
      "8. G       216 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (216)  networkx      |   (56)   a networkx graph\n",
      "\n",
      "9. value   212 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (83)   tensorflow    |   (16)   the value associated with the cli option.\n",
      "    (31)   google        |   (8)    a `tensor`.\n",
      "    (18)   awscli        |   (6)    `float` or `double` `tensor`.\n",
      "    (13)   werkzeug      |   (3)    the value to set.\n",
      "    (9)    asn1crypto    |   (3)    value to use to fill holes (e.g. 0), alternately a dict/ser [...]\n",
      "\n",
      "10.inputs  209 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (198)  tensorflow    |   (13)   tensor input.\n",
      "    (8)    magenta       |   (12)   a tensor of size [batch_size, height, width, channels].\n",
      "    (2)    theano        |   (9)    input tensor, or list/tuple of input tensors.\n",
      "    (1)    tflearn       |   (8)    input tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_descs_per_arg():\n",
    "    ARGS= 10\n",
    "    TOP_DESC = 5\n",
    "    \n",
    "    arg_names = Counter(x['arg_name'] for x in TOTAL)\n",
    "    mc = arg_names.most_common()\n",
    "    \n",
    "    tally = {}\n",
    "    for d in TOTAL:\n",
    "        name = d['arg_name']\n",
    "        if name in tally:\n",
    "            tally[name][\"desc\"].append(d['arg_desc'].lower())\n",
    "            tally[name][\"pkg\"].append(d['pkg'])\n",
    "        else:\n",
    "            tally[name] = {\"desc\": [d['arg_desc']], \"pkg\": [d['pkg']]}\n",
    "    \n",
    "    tuple_tally = {k: (Counter(v['desc']).most_common(), \n",
    "                       Counter(v['pkg']).most_common()) for k,v in tally.items()}\n",
    "    \n",
    "    for i, (arg, c) in enumerate(mc[:ARGS]):\n",
    "        \n",
    "        line = [\n",
    "            str.ljust(\"{}.\".format(i+1), 3, \" \"),\n",
    "            str.ljust(\"{}\".format(arg), 7, \" \"),\n",
    "            str.rjust(\"{} \".format(c), 5, \" \"),\n",
    "            \"\\n\",\n",
    "            str.ljust(\"    (TOP PKG) \", 11, \" \"),\n",
    "            str.ljust(\"\", 11, \" \"),\n",
    "            str.ljust(\"|  \", 6, \" \"),\n",
    "            str.ljust(\"  (TOP DESC)\", 5, \" \"),\n",
    "            str.ljust(\"\", 5, \" \"),\n",
    "            \"\\n\"\n",
    "        ]\n",
    "        \n",
    "        for (desc, cd), (repo, cr) in list(zip(*tuple_tally[arg]))[:TOP_DESC]:\n",
    "            trim = 60\n",
    "            ellipse = \" [...]\" if len(desc) > trim else \"\"\n",
    "            sub_lines = [\n",
    "                str.ljust(\"    ({}) \".format(cr), 11, \" \"),\n",
    "                str.ljust(\"{}\".format(repo), 14, \" \"),\n",
    "                str.ljust(\"|\".format(repo), 3, \" \"),\n",
    "                str.ljust(\" ({})\".format(cd), 7, \" \"),\n",
    "                str.ljust(\"{}\".format(desc[:trim]+ellipse), 5, \" \"),\n",
    "                \"\\n\"\n",
    "            ]\n",
    "            line.extend(sub_lines)\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "#     func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "count_descs_per_arg()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (1056)  a name for the operation (optional).\n",
      "            name              (1056)    |      tensorflow      (1056) \n",
      "\n",
      "2. (94)  the amount of time, in seconds, to wait for the request to complete.\n",
      "note that if ``retry`` is specified, the timeout applies to each individual\n",
      "attempt.\n",
      "            timeout           (94)      |      google          (94)  \n",
      "\n",
      "3. (92)  a retry object used to retry requests. if ``none`` is specified,\n",
      "requests will not be retried.\n",
      "            retry             (92)      |      google          (92)  \n",
      "\n",
      "4. (70)  optional op name.\n",
      "            name              (70)      |      tensorflow      (70)  \n",
      "\n",
      "5. (69)  input tensor.\n",
      "            labeled_tensor    (21)      |      tensorflow      (69)  \n",
      "\n",
      "6. (66)  an optional `string`. defaults to `\"\"`.\n",
      "            container         (32)      |      tensorflow      (66)  \n",
      "\n",
      "7. (66)  overrides the default settings for this call, e.g, timeout, retries\n",
      "etc.\n",
      "            options           (66)      |      google          (66)  \n",
      "\n",
      "8. (65)  a `tensor`.\n",
      "            input             (22)      |      tensorflow      (65)  \n",
      "\n",
      "9. (62)  a `tensor` of type `float32`.\n",
      "            flow_in           (14)      |      tensorflow      (62)  \n",
      "\n",
      "10.(57)  a `tensor` of type `int32`.\n",
      "            indices           (10)      |      tensorflow      (57)  \n",
      "\n",
      "11.(56)  a networkx graph\n",
      "            g                 (55)      |      networkx        (56)  \n",
      "\n",
      "12.(51)  input array.\n",
      "            a                 (29)      |      scipy           (35)  \n",
      "            arr               (5)       |      numpy           (9)   \n",
      "            m                 (5)       |      dask            (3)   \n",
      "            val               (2)       |      pandas          (2)   \n",
      "            x                 (2)       |      skimage         (1)   \n",
      "\n",
      "13.(46)  an optional variable_scope name.\n",
      "            name              (46)      |      tensorflow      (46)  \n",
      "\n",
      "14.(44)  input image.\n",
      "            image             (44)      |      skimage         (44)  \n",
      "\n",
      "15.(44)  tensor or variable.\n",
      "            x                 (36)      |      tensorflow      (44)  \n",
      "\n",
      "16.(42)  if int, random_state is the seed used by the random number generator;\n",
      "if randomstate instance, random_state is the random number generator;\n",
      "if none, the random number generator is the randomstate instance used\n",
      "by `np.random`.\n",
      "            random_state      (42)      |      sklearn         (42)  \n",
      "\n",
      "17.(42)  a `tensor` of type `resource`. should be from a variable().\n",
      "            var               (16)      |      tensorflow      (42)  \n",
      "\n",
      "18.(37)  a name for this operation (optional).\n",
      "            name              (37)      |      tensorflow      (37)  \n",
      "\n",
      "19.(36)  a list of `tf.dtypes` that has length `>= 1`.\n",
      "            output_types      (30)      |      tensorflow      (36)  \n",
      "\n",
      "20.(34)  a `tensor`. must have the same type as `x`.\n",
      "            y                 (24)      |      tensorflow      (34)  \n",
      "\n",
      "21.(34)  the root of the parse tree that matched the fixer.\n",
      "            node              (34)      |      libfuturize     (19)  \n",
      "\n",
      "22.(33)  the input array.\n",
      "            input             (27)      |      scipy           (30)  \n",
      "            a                 (3)       |      dask            (2)   \n",
      "            x                 (2)       |      skimage         (1)   \n",
      "\n",
      "23.(33)  a `tensor` of type `string`.\n",
      "            handle            (10)      |      tensorflow      (33)  \n",
      "\n",
      "24.(32)  a dict mapping symbolic names to part of the match.\n",
      "            results           (32)      |      libfuturize     (18)  \n",
      "\n",
      "25.(31)  a string, the name of the layer.\n",
      "            name              (31)      |      tensorflow      (31)  \n",
      "\n",
      "26.(31)  a list of shapes (each a `tf.tensorshape` or list of `ints`) that\n",
      "has length `>= 1`.\n",
      "            output_shapes     (31)      |      tensorflow      (31)  \n",
      "\n",
      "27.(31)  a `tensor` of type `variant`.\n",
      "            input_dataset     (22)      |      tensorflow      (31)  \n",
      "\n",
      "28.(30)  the scope for the operations performed in computing the loss.\n",
      "            scope             (30)      |      tensorflow      (30)  \n",
      "\n",
      "29.(30)  `\"same\", \"valid\"`. the type of padding algorithm to use.\n",
      "            padding           (30)      |      tensorflow      (30)  \n",
      "\n",
      "30.(28)  boolean, whether the layer uses a bias.\n",
      "            use_bias          (28)      |      tensorflow      (28)  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_args_per_desc():\n",
    "    ARGS= 30\n",
    "    TOP_DESC = 5\n",
    "    \n",
    "    arg_desc = Counter(x['arg_desc'].strip().lower() for x in TOTAL)\n",
    "    mc = arg_desc.most_common()\n",
    "    \n",
    "    tally = {}\n",
    "    for d in TOTAL:\n",
    "        desc = d['arg_desc'].strip().lower()\n",
    "        if desc in tally:\n",
    "            tally[desc][\"name\"].append(d['arg_name'].lower())\n",
    "            tally[desc][\"pkg\"].append(d['pkg'])\n",
    "        else:\n",
    "            tally[desc] = {\"name\": [d['arg_name']], \"pkg\": [d['pkg']]}\n",
    "    \n",
    "    tuple_tally = {k: (Counter(v['name']).most_common(), \n",
    "                       Counter(v['pkg']).most_common()) for k,v in tally.items()}\n",
    "    \n",
    "    for i, (arg, c) in enumerate(mc[:ARGS]):\n",
    "        \n",
    "        line = [\n",
    "            str.ljust(\"{}.\".format(i+1), 3, \" \"),\n",
    "            str.rjust(\"({})  \".format(c), 5, \" \"),\n",
    "            str.ljust(\"{}\".format(arg), 7, \" \"),\n",
    "            \"\\n\",\n",
    "        ]\n",
    "        \n",
    "        for (name, cd), (repo, cr) in list(zip(*tuple_tally[arg]))[:TOP_DESC]:\n",
    "            sub_lines = [\n",
    "                str.ljust(\"            {}\".format(name), 30, \" \"),\n",
    "                str.ljust(\"({})\".format(cd), 10, \" \"),\n",
    "                str.ljust(\"|\", 7, \" \"),\n",
    "                \n",
    "                str.ljust(\"{}\".format(repo), 15, \" \"),\n",
    "                str.ljust(\" ({}) \".format(cr), 7, \" \"),\n",
    "\n",
    "                \"\\n\"\n",
    "            ]\n",
    "            line.extend(sub_lines)\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "#     func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "count_args_per_desc()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing Duplicates now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
