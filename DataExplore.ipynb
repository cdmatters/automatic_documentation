{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from project.data.preprocessed.unsplit import unsplit_data as UNSPLIT\n",
    "from project.data.preprocessed.split import split_data as SPLIT\n",
    "from project.utils.tokenize import nltk_tok\n",
    "\n",
    "UNSPLIT = UNSPLIT()\n",
    "\n",
    "TOTAL = []\n",
    "TOTAL.extend(UNSPLIT.train)\n",
    "TOTAL.extend(UNSPLIT.valid)\n",
    "# TOTAL.extend(UNSPLIT.test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_and_bottom(counter_obj, count, name, cols=2, width=35):\n",
    "    mc = counter_obj.most_common()\n",
    "    top_x = mc[:count]\n",
    "    bottom_x = mc[-count:]\n",
    "    \n",
    "    top = \"\\n\".join(\"{}. {}\".format(i+1, x) for i,x in enumerate(top_x))\n",
    "    bottom = \"\\n\".join(\"{}. {}\".format(i+1, x) for i,x in enumerate(reversed(bottom_x)))\n",
    "    \n",
    "    s = '''TOP {count} {name}\\n{top}\\nBOTTOM {count} {name}\\n{bottom}'''.format(\n",
    "        count=count, name=name, top=top, bottom=bottom\n",
    "    )\n",
    "    print(to_columns(s, cols, width))\n",
    "    return mc\n",
    "\n",
    "def to_columns(string, cols, width):\n",
    "    lines = string.split(\"\\n\")\n",
    "    lpc = int(len(lines) / cols)\n",
    "    columns = [lines[i*lpc:(i+1)*lpc] for i in range(cols)]\n",
    "    \n",
    "    max_c = max([len(c) for c in columns])\n",
    "    for c in columns:\n",
    "        size = len(c)\n",
    "        for i in range(max_c - size):\n",
    "            c.append(\" \")\n",
    "    \n",
    "    final_text = []\n",
    "    for i in range(len(lines)):\n",
    "        final_text.append(str.ljust(columns[i % cols][(i // cols)], width, \" \"))\n",
    "        if i % cols == cols-1:\n",
    "            final_text.append('\\n')\n",
    "    return \"\".join(final_text)\n",
    "\n",
    "def get_histogram(counter, bins, name):\n",
    "    counts = [n[1] for n in counter]\n",
    "    total = sum(counts)\n",
    "    args = len(counter)\n",
    "    meta_counter = Counter(counts)\n",
    "    \n",
    "    h = np.histogram(counts, bins)\n",
    "\n",
    "    lines = [ \n",
    "        \"Histogram: {}\".format(name),\n",
    "        \"\\n\",\n",
    "        str.ljust(\"Bin\", 10, \" \"),\n",
    "        str.rjust(\"Count\", 7, \" \"),\n",
    "        str.rjust(\"% of names\", 12, \" \"),\n",
    "        str.rjust(\"% of vars\", 10, \" \"), \n",
    "        str.rjust(\"%-ile vars \", 13, \" \"), \n",
    "        \"\\n\",\n",
    "    ]\n",
    "    \n",
    "    cumulative = 0 \n",
    "    for i in range(1, len(h[1])-1):\n",
    "        bucket_min, bucket_max = h[1][i], h[1][i+1] \n",
    "        lines.append(str.ljust(\"{}-{}\".format(bucket_min, bucket_max), 10, \" \"))\n",
    "        lines.append(str.rjust(\"{}\".format(h[0][i]), 7, \" \"))\n",
    "        lines.append(str.rjust(\"{:.3f}\".format(100*h[0][i]/args), 11, \" \"))\n",
    "        \n",
    "        tot = 0\n",
    "        for i in range(bucket_min, bucket_max):\n",
    "            if i in meta_counter:\n",
    "                tot += i * meta_counter[i]\n",
    "        lines.append(str.rjust(\"{:.3f}\".format(100*tot/total), 11, \" \"))\n",
    "        cumulative += 100*tot/total\n",
    "        lines.append(str.rjust(\"{:.2f}\".format(cumulative), 11, \" \"))\n",
    "        \n",
    "        lines.append(\"\\n\")\n",
    "    return \"\".join(lines)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 Argument Names              BOTTOM 10 Argument Names           \n",
      "1. ('name', 1917)                  1. ('partial_args', 1)             \n",
      "2. ('x', 439)                      2. ('release_conn', 1)             \n",
      "3. ('kwargs', 303)                 3. ('xfrm21', 1)                   \n",
      "4. ('axis', 263)                   4. ('sparse_features', 1)          \n",
      "5. ('dtype', 260)                  5. ('end_inclusive', 1)            \n",
      "6. ('a', 230)                      6. ('xyz', 1)                      \n",
      "7. ('G', 227)                      7. ('pool_timeout', 1)             \n",
      "8. ('inputs', 224)                 8. ('line_length', 1)              \n",
      "9. ('input', 223)                  9. ('root_source', 1)              \n",
      "10. ('value', 210)                 10. ('stdoffset', 1)               \n",
      "\n",
      "TOP 10 Function Names              BOTTOM 10 Function Names           \n",
      "1. ('fit', 122)                    1. ('relabel_gexf_graph', 1)       \n",
      "2. ('transform', 102)              2. ('note_number_to_drum_name', 1) \n",
      "3. ('train', 77)                   3. ('unmute', 1)                   \n",
      "4. ('evaluate', 71)                4. ('AfterInput', 1)               \n",
      "5. ('get', 61)                     5. ('vgg11_bn', 1)                 \n",
      "6. ('conv2d', 59)                  6. ('from_prufer_sequence', 1)     \n",
      "7. ('Client', 52)                  7. ('assert_variables_initialized', 1)\n",
      "8. ('update', 46)                  8. ('parse_flags_with_usage', 1)   \n",
      "9. ('add', 45)                     9. ('uirfft2', 1)                  \n",
      "10. ('specgram', 45)               10. ('get_minus_sign_symbol', 1)   \n",
      "\n",
      "Histogram: Arg Names                                        Histogram: Func Names                                       \n",
      "Bin         Count  % of names % of vars  %-ile vars         Bin         Count  % of names % of vars  %-ile vars         \n",
      "1-2          3681     53.550     11.738      11.74          1-2          2453     28.774      7.822       7.82          \n",
      "2-3          1297     18.868      8.272      20.01          2-3          1911     22.416     12.188      20.01          \n",
      "3-4           544      7.914      5.204      25.21          3-4          1198     14.053     11.460      31.47          \n",
      "4-5           300      4.364      3.827      29.04          4-5           837      9.818     10.676      42.15          \n",
      "5-10          539      7.841     10.989      40.03          5-10         1649     19.343     32.930      75.08          \n",
      "10-20         272      3.957     11.464      51.49          10-20         384      4.504     15.523      90.60          \n",
      "20-50         166      2.415     15.938      67.43          20-50          86      1.009      7.666      98.27          \n",
      "50-100         46      0.669     10.185      77.61          50-100          5      0.059      1.020      99.29          \n",
      "100-200        19      0.276      8.686      86.30          100-200         2      0.023      0.714     100.00          \n",
      "200-500         9      0.131      7.586      93.89          200-500         0      0.000      0.000     100.00          \n",
      "500-3000        1      0.015      6.113     100.00          500-3000        0      0.000      0.000     100.00          \n",
      "                                                                                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 10\n",
    "def counts():\n",
    "    arg_names = Counter(x['arg_name'] for x in TOTAL)\n",
    "    func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "    mc_arg_name = print_top_and_bottom(arg_names, TOP_N, \"Argument Names\")\n",
    "    mc_func_name = print_top_and_bottom(func_names, TOP_N, \"Function Names\")\n",
    "    \n",
    "    name_bins =  [0,1,2,3,4,5,10,20,50,100,200,500,3000]\n",
    "    name_h = get_histogram(mc_arg_name, name_bins, \"Arg Names\")\n",
    "    func_bins =  [0,1,2,3,4,5,10,20,50,100,200]\n",
    "    func_h = get_histogram(mc_func_name, name_bins, \"Func Names\")\n",
    "    print(to_columns(name_h + '\\n' + func_h , 2, 60))\n",
    "\n",
    "        \n",
    "counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Unique [Arg, Desc]\n",
      "\n",
      "N. Count  [Arg, Desc]\n",
      "1  1057   ['name', 'a name for the operation ( optional ) .']\n",
      "\n",
      "2  95     ['retry', 'a retry object used to retry requests . if `` none `` is specified , requests will not be retried .']\n",
      "\n",
      "3  83     ['timeout', 'the amount of time , in seconds , to wait for the request to complete . note that if `` retry `` is specified , the timeout applies to each individual attempt .']\n",
      "\n",
      "4  69     ['name', 'optional op name .']\n",
      "\n",
      "5  59     ['options', 'overrides the default settings for this call , e.g , timeout , retries etc .']\n",
      "\n",
      "6  57     ['G', 'a networkx graph']\n",
      "\n",
      "7  44     ['image', 'input image .']\n",
      "\n",
      "8  41     ['name', 'an optional variable_scope name .']\n",
      "\n",
      "9  39     ['random_state', 'if int , random_state is the seed used by the random number generator ; if randomstate instance , random_state is the random number generator ; if none , the random number generator is the randomstate instance used by ` np.random ` .']\n",
      "\n",
      "10 37     ['name', 'a name for this operation ( optional ) .']\n",
      "\n",
      "11 34     ['padding', \"` `` same '' , `` valid '' ` . the type of padding algorithm to use .\"]\n",
      "\n",
      "12 33     ['updates_collections', 'an optional list of collections that ` update_op ` should be added to .']\n",
      "\n",
      "13 32     ['x', 'tensor or variable .']\n",
      "\n",
      "14 31     ['name', 'a string , the name of the layer .']\n",
      "\n",
      "15 29     ['node', 'the root of the parse tree that matched the fixer .']\n",
      "\n",
      "16 28     ['padding', \"one of ` `` valid '' ` or ` `` same '' ` ( case-insensitive ) .\"]\n",
      "\n",
      "17 28     ['input', 'the input array .']\n",
      "\n",
      "18 28     ['output_types', 'a list of ` tf.dtypes ` that has length ` > = 1 ` .']\n",
      "\n",
      "19 28     ['level', 'broadcast across a level , matching index values on the passed multiindex level']\n",
      "\n",
      "20 28     ['container', \"an optional ` string ` . defaults to ` `` '' ` .\"]\n",
      "\n",
      "\n",
      "\n",
      "Histogram: Unique Names + Desc\n",
      "Bin         Count  % of names % of vars  %-ile vars \n",
      "1-2         14956     77.009     47.691      47.69\n",
      "2-3          2717     13.990     17.328      65.02\n",
      "3-4           705      3.630      6.744      71.76\n",
      "4-5           377      1.941      4.809      76.57\n",
      "5-10          480      2.472      9.483      86.06\n",
      "10-20         135      0.695      5.644      91.70\n",
      "20-50          45      0.232      3.772      95.47\n",
      "50-100          5      0.026      1.158      96.63\n",
      "100-200         0      0.000      0.000      96.63\n",
      "200-3000        1      0.005      3.371     100.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 20\n",
    "def check_for_duplicates():\n",
    "    div = \"<!!S!!>\"\n",
    "    arg_names = Counter(x['arg_name'] + div + \" \".join(nltk_tok(x['arg_desc'])) for x in TOTAL)\n",
    "    mc = arg_names.most_common()\n",
    "    print(\"Check for Unique [Arg, Desc]\\n\")\n",
    "    print(\"{}\".format(\"N. Count  [Arg, Desc]\"))\n",
    "    \n",
    "    for i, (arg_desc, c) in enumerate(mc[:TOP_N]):\n",
    "        line = [\n",
    "            str.ljust(\"{}\".format(i+1), 3, \" \"),\n",
    "            str.ljust(\"{}\".format(c), 7, \" \"),\n",
    "            \"{}\".format(arg_desc.split(div)),\n",
    "            \"\\n\"\n",
    "        ]\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "    print()\n",
    "    print()\n",
    "    name_bins =  [0,1,2,3,4,5,10,20,50,100,200,3000]\n",
    "    name_h = get_histogram(mc, name_bins, \"Unique Names + Desc\")\n",
    "    print(name_h)\n",
    "    \n",
    "check_for_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. name   1917 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (1654) tensorflow    |   (1057) a name for the operation (optional).\n",
      "    (51)   google        |   (69)   optional op name.\n",
      "    (50)   tflearn       |   (41)   an optional variable_scope name.\n",
      "    (14)   external      |   (37)   a name for this operation (optional).\n",
      "    (13)   absl          |   (31)   a string, the name of the layer.\n",
      "\n",
      "2. x       439 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (300)  tensorflow    |   (32)   tensor or variable.\n",
      "    (43)   matplotlib    |   (17)   a tensor or variable.\n",
      "    (35)   scipy         |   (14)   `bfloat16`, `half`, `float32`, `float64`, `complex64`, `com [...]\n",
      "    (12)   tflearn       |   (12)   numeric `tensor`.\n",
      "    (9)    dask          |   (10)   array or sequence containing the data\n",
      "\n",
      "3. kwargs  303 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (62)   tensorflow    |   (12)   additional keyword arguments which will be passed to the ap [...]\n",
      "    (47)   google        |   (11)   optional arguments that ``request`` takes.\n",
      "    (23)   dask          |   (8)    standard layer keyword arguments.\n",
      "    (21)   mir_eval      |   (7)    additional properties to be set on the :class:`~.google.clo [...]\n",
      "    (18)   librosa       |   (5)    keyword arguments to pass to base method.\n",
      "\n",
      "4. axis    263 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (85)   tensorflow    |   (14)   axis to broadcast over\n",
      "    (61)   pandas        |   (7)    the dimensions to reduce. if `none` (the default), reduces  [...]\n",
      "    (54)   scipy         |   (4)    the index or the name of the axis. 0 is equivalent to none  [...]\n",
      "    (20)   dask          |   (4)    a `tensor` of type `int64`.\n",
      "    (17)   librosa       |   (4)    the axis or axes that were summed.\n",
      "\n",
      "5. dtype   260 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (161)  tensorflow    |   (11)   a `tf.dtype`.\n",
      "    (39)   scipy         |   (8)    the data type. only floating point types are supported.\n",
      "    (11)   networkx      |   (7)    default data type for internal matrices. set to np.float32  [...]\n",
      "    (9)    pandas        |   (6)    the type of the output.\n",
      "    (8)    dask          |   (6)    overrides the data type of the result.\n",
      "\n",
      "6. a       230 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (99)   scipy         |   (25)   input array.\n",
      "    (71)   tensorflow    |   (7)    input array\n",
      "    (25)   dask          |   (7)    input data.\n",
      "    (25)   numpy         |   (7)    input array, can be complex.\n",
      "    (3)    seaborn       |   (6)    a `tensor` of type `float32`.\n",
      "\n",
      "7. G       227 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (226)  networkx      |   (56)   a networkx graph\n",
      "    (1)    skimage       |   (14)   undirected graph\n",
      "\n",
      "8. inputs  224 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (209)  tensorflow    |   (11)   a tensor of size [batch_size, height, width, channels].\n",
      "    (9)    magenta       |   (11)   tensor input.\n",
      "    (4)    theano        |   (9)    input tensor.\n",
      "    (2)    tflearn       |   (9)    input tensor(s).\n",
      "\n",
      "9. input   223 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (140)  tensorflow    |   (28)   the input array.\n",
      "    (56)   scipy         |   (20)   a `tensor`.\n",
      "    (15)   torch         |   (8)    a `tensor` of type `complex64`. a complex64 tensor.\n",
      "    (4)    webencodings  |   (6)    a `tensor` of type `complex64`.\n",
      "    (2)    click         |   (5)    input\n",
      "\n",
      "10.value   210 \n",
      "    (TOP PKG)            |       (TOP DESC)     \n",
      "    (79)   tensorflow    |   (13)   the value associated with the cli option.\n",
      "    (31)   google        |   (8)    a `tensor`.\n",
      "    (16)   awscli        |   (4)    any value accepted by this consumer.\n",
      "    (10)   pandas        |   (4)    value to use to fill holes (e.g. 0), alternately a dict/ser [...]\n",
      "    (9)    werkzeug      |   (3)    the value to be converted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_descs_per_arg():\n",
    "    ARGS= 10\n",
    "    TOP_DESC = 5\n",
    "    \n",
    "    arg_names = Counter(x['arg_name'] for x in TOTAL)\n",
    "    mc = arg_names.most_common()\n",
    "    \n",
    "    tally = {}\n",
    "    for d in TOTAL:\n",
    "        name = d['arg_name']\n",
    "        if name in tally:\n",
    "            tally[name][\"desc\"].append(d['arg_desc'].lower())\n",
    "            tally[name][\"pkg\"].append(d['pkg'])\n",
    "        else:\n",
    "            tally[name] = {\"desc\": [d['arg_desc']], \"pkg\": [d['pkg']]}\n",
    "    \n",
    "    tuple_tally = {k: (Counter(v['desc']).most_common(), \n",
    "                       Counter(v['pkg']).most_common()) for k,v in tally.items()}\n",
    "    \n",
    "    for i, (arg, c) in enumerate(mc[:ARGS]):\n",
    "        \n",
    "        line = [\n",
    "            str.ljust(\"{}.\".format(i+1), 3, \" \"),\n",
    "            str.ljust(\"{}\".format(arg), 7, \" \"),\n",
    "            str.rjust(\"{} \".format(c), 5, \" \"),\n",
    "            \"\\n\",\n",
    "            str.ljust(\"    (TOP PKG) \", 11, \" \"),\n",
    "            str.ljust(\"\", 11, \" \"),\n",
    "            str.ljust(\"|  \", 6, \" \"),\n",
    "            str.ljust(\"  (TOP DESC)\", 5, \" \"),\n",
    "            str.ljust(\"\", 5, \" \"),\n",
    "            \"\\n\"\n",
    "        ]\n",
    "        \n",
    "        for (desc, cd), (repo, cr) in list(zip(*tuple_tally[arg]))[:TOP_DESC]:\n",
    "            trim = 60\n",
    "            ellipse = \" [...]\" if len(desc) > trim else \"\"\n",
    "            sub_lines = [\n",
    "                str.ljust(\"    ({}) \".format(cr), 11, \" \"),\n",
    "                str.ljust(\"{}\".format(repo), 14, \" \"),\n",
    "                str.ljust(\"|\".format(repo), 3, \" \"),\n",
    "                str.ljust(\" ({})\".format(cd), 7, \" \"),\n",
    "                str.ljust(\"{}\".format(desc[:trim]+ellipse), 5, \" \"),\n",
    "                \"\\n\"\n",
    "            ]\n",
    "            line.extend(sub_lines)\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "#     func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "count_descs_per_arg()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (1057)  a name for the operation (optional).\n",
      "            name              (1057)    |      tensorflow      (1057) \n",
      "\n",
      "2. (95)  a retry object used to retry requests. if ``none`` is specified, requests will not be retried.\n",
      "            retry             (95)      |      google          (95)  \n",
      "\n",
      "3. (83)  the amount of time, in seconds, to wait for the request to complete. note that if ``retry`` is specified, the timeout applies to each individual attempt.\n",
      "            timeout           (83)      |      google          (83)  \n",
      "\n",
      "4. (70)  input tensor.\n",
      "            labeled_tensor    (20)      |      tensorflow      (70)  \n",
      "\n",
      "5. (69)  optional op name.\n",
      "            name              (69)      |      tensorflow      (69)  \n",
      "\n",
      "6. (59)  overrides the default settings for this call, e.g, timeout, retries etc.\n",
      "            options           (59)      |      google          (59)  \n",
      "\n",
      "7. (59)  a `tensor` of type `float32`.\n",
      "            flow_in           (12)      |      tensorflow      (59)  \n",
      "\n",
      "8. (58)  a `tensor`.\n",
      "            input             (20)      |      tensorflow      (58)  \n",
      "\n",
      "9. (58)  an optional `string`. defaults to `\"\"`.\n",
      "            container         (28)      |      tensorflow      (58)  \n",
      "\n",
      "10.(57)  a networkx graph\n",
      "            g                 (56)      |      networkx        (57)  \n",
      "\n",
      "11.(52)  a `tensor` of type `int32`.\n",
      "            indices           (13)      |      tensorflow      (52)  \n",
      "\n",
      "12.(50)  input array.\n",
      "            a                 (29)      |      scipy           (35)  \n",
      "            arr               (7)       |      numpy           (8)   \n",
      "            m                 (4)       |      dask            (4)   \n",
      "            x                 (3)       |      pandas          (2)   \n",
      "            x1                (1)       |      skimage         (1)   \n",
      "\n",
      "13.(45)  a `tensor` of type `resource`. should be from a variable().\n",
      "            var               (16)      |      tensorflow      (45)  \n",
      "\n",
      "14.(44)  input image.\n",
      "            image             (44)      |      skimage         (44)  \n",
      "\n",
      "15.(41)  an optional variable_scope name.\n",
      "            name              (41)      |      tensorflow      (41)  \n",
      "\n",
      "16.(40)  tensor or variable.\n",
      "            x                 (32)      |      tensorflow      (40)  \n",
      "\n",
      "17.(39)  if int, random_state is the seed used by the random number generator; if randomstate instance, random_state is the random number generator; if none, the random number generator is the randomstate instance used by `np.random`.\n",
      "            random_state      (39)      |      sklearn         (39)  \n",
      "\n",
      "18.(37)  a `tensor`. must have the same type as `x`.\n",
      "            y                 (25)      |      tensorflow      (37)  \n",
      "\n",
      "19.(37)  a name for this operation (optional).\n",
      "            name              (37)      |      tensorflow      (37)  \n",
      "\n",
      "20.(36)  a `tensor` of type `string`.\n",
      "            handle            (9)       |      tensorflow      (36)  \n",
      "\n",
      "21.(35)  the input array.\n",
      "            input             (28)      |      scipy           (32)  \n",
      "            a                 (4)       |      dask            (2)   \n",
      "            x                 (2)       |      skimage         (1)   \n",
      "\n",
      "22.(35)  a list of `tf.dtypes` that has length `>= 1`.\n",
      "            output_types      (28)      |      tensorflow      (35)  \n",
      "\n",
      "23.(34)  `\"same\", \"valid\"`. the type of padding algorithm to use.\n",
      "            padding           (34)      |      tensorflow      (34)  \n",
      "\n",
      "24.(33)  an optional list of collections that `update_op` should be added to.\n",
      "            updates_collections(33)      |      tensorflow      (33)  \n",
      "\n",
      "25.(32)  a `tensor` of type `variant`.\n",
      "            input_dataset     (25)      |      tensorflow      (32)  \n",
      "\n",
      "26.(31)  a string, the name of the layer.\n",
      "            name              (31)      |      tensorflow      (31)  \n",
      "\n",
      "27.(31)  a mutable `tensor`. must have the same type as `var`. should be from a variable().\n",
      "            accum             (11)      |      tensorflow      (31)  \n",
      "\n",
      "28.(30)  an optional `int`. defaults to `0`.\n",
      "            seed2             (7)       |      tensorflow      (30)  \n",
      "\n",
      "29.(29)  the root of the parse tree that matched the fixer.\n",
      "            node              (29)      |      libpasteurize   (16)  \n",
      "\n",
      "30.(28)  the input tensor.\n",
      "            labeled_tensor    (26)      |      tensorflow      (28)  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_args_per_desc():\n",
    "    ARGS= 30\n",
    "    TOP_DESC = 5\n",
    "    \n",
    "    arg_desc = Counter(x['arg_desc'].strip().lower() for x in TOTAL)\n",
    "    mc = arg_desc.most_common()\n",
    "    \n",
    "    tally = {}\n",
    "    for d in TOTAL:\n",
    "        desc = d['arg_desc'].strip().lower()\n",
    "        if desc in tally:\n",
    "            tally[desc][\"name\"].append(d['arg_name'].lower())\n",
    "            tally[desc][\"pkg\"].append(d['pkg'])\n",
    "        else:\n",
    "            tally[desc] = {\"name\": [d['arg_name']], \"pkg\": [d['pkg']]}\n",
    "    \n",
    "    tuple_tally = {k: (Counter(v['name']).most_common(), \n",
    "                       Counter(v['pkg']).most_common()) for k,v in tally.items()}\n",
    "    \n",
    "    for i, (arg, c) in enumerate(mc[:ARGS]):\n",
    "        \n",
    "        line = [\n",
    "            str.ljust(\"{}.\".format(i+1), 3, \" \"),\n",
    "            str.rjust(\"({})  \".format(c), 5, \" \"),\n",
    "            str.ljust(\"{}\".format(arg), 7, \" \"),\n",
    "            \"\\n\",\n",
    "        ]\n",
    "        \n",
    "        for (name, cd), (repo, cr) in list(zip(*tuple_tally[arg]))[:TOP_DESC]:\n",
    "            sub_lines = [\n",
    "                str.ljust(\"            {}\".format(name), 30, \" \"),\n",
    "                str.ljust(\"({})\".format(cd), 10, \" \"),\n",
    "                str.ljust(\"|\", 7, \" \"),\n",
    "                \n",
    "                str.ljust(\"{}\".format(repo), 15, \" \"),\n",
    "                str.ljust(\" ({}) \".format(cr), 7, \" \"),\n",
    "\n",
    "                \"\\n\"\n",
    "            ]\n",
    "            line.extend(sub_lines)\n",
    "        print(\"\".join(line))\n",
    "        \n",
    "#     func_names = Counter(x['name'] for x in TOTAL)\n",
    "    \n",
    "count_args_per_desc()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'project.utils.code_tokenize' from '/home/eweezy/ucl/project/project/utils/code_tokenize.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import project.utils.code_tokenize as ct\n",
    "\n",
    "import importlib\n",
    "importlib.reload(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 20 Processes\n",
      "Closed Processes427444 115 27444 153 27444175 27444 2744427444 251 27444 252 2744427444 252 27444 27444 252 27444 252 27444 252 27444252 27444252 27444 252 27444252 27444 27444252 27444 27444274442744427444 339 27444 371 27444386 27444422 27444 445 27444 445 27444 445 27444 448 27444448 27444 27444448 27444 448 274442744427444 452 27444 454 27444473 27444 485 27444 485 27444 519 27444 519 27444527 27444 2744427444 529 27444529 27444 2744427444 529 2744427444 531 27444 531 27444 532 27444 2744427444 27444 568 27444568 27444 2744427444 2744427444581 27444 581 27444595 27444911 2744427444 1091 27444 1514 27444 1514 27444 27444 1616 27444 1731 274441769 2744427444 274442069 27444 2166 27444 2367 2744427444 2573 27444 2682 27444 2800 27444 3199 27444 2744427444 27444 4101 27444 2744427444 4514 2744427444 5073 274442744427444 7545 27444\n",
      "Starting 20 Processes\n",
      "Closed Processes16103 3916 39163916 118 39163916 391639163916122 3916134 3916 3916 200 3916 376 3916\n"
     ]
    }
   ],
   "source": [
    "train = ct.return_populated_codepath(UNSPLIT.train)\n",
    "valid = ct.return_populated_codepath(UNSPLIT.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 Top Paths                   \n",
      "1. ('Name <- keyword <- Call -> keyword', 59965)\n",
      "2. ('Name <- Call -> Name', 57616) \n",
      "3. ('Name <- keyword <- Call -> keyword -> Name', 57014)\n",
      "4. ('Name <- Call -> Attribute', 25031)\n",
      "5. ('Name <- Call -> Attribute -> Name', 20282)\n",
      "6. ('Name <- keyword <- Call <- Assign <- If -> Assign -> Name', 20006)\n",
      "7. ('Name <- Call <- Assign <- Try <- If -> Assign -> Name', 16526)\n",
      "8. ('Name <- keyword <- Call <- Assign <- If -> Try -> Assign -> Call -> Name', 16394)\n",
      "9. ('Name <- Call <- Assign <- Try <- If -> Assign -> Call -> keyword', 15707)\n",
      "10. ('Name <- Call <- Assign <- Try <- If -> Assign -> Call -> keyword -> Name', 15703)\n",
      "11. ('Name <- keyword <- Call -> Name', 15219)\n",
      "12. ('Name <- Call <- Assign <- FunctionDef -> Assign -> Name', 14324)\n",
      "13. ('Name <- Call <- Assign <- FunctionDef -> Assign -> Call -> Name', 14205)\n",
      "14. ('Name <- Assign <- FunctionDef <- ClassDef -> FunctionDef', 13509)\n",
      "15. ('Name <- keyword <- Call <- Assign <- If -> Try -> Assign -> Call -> Attribute', 12899)\n",
      "16. ('Name <- Assign <- FunctionDef <- ClassDef -> FunctionDef -> Assign -> Name', 12666)\n",
      "17. ('Name <- keyword <- Call <- Assign -> Tuple -> Name', 11919)\n",
      "18. ('Name <- Call -> keyword', 11618)\n",
      "19. ('Name <- keyword <- Call <- Assign <- If -> Expr -> Call -> Name', 11450)\n",
      "20. ('Name <- Assign <- FunctionDef -> Assign -> Name', 11139)\n",
      "BOTTOM 20 Top Paths                \n",
      "1. ('Name <- Dict <- Assign <- FunctionDef -> Assign -> Call -> Subscript -> Index -> Str', 1)\n",
      "2. ('Str <- Dict <- Assign <- FunctionDef -> Assign -> Call -> Subscript -> Index -> Str', 1)\n",
      "3. ('Name <- Dict <- Assign <- FunctionDef -> Assign -> Call -> keyword -> NameConstant', 1)\n",
      "4. ('Str <- Dict <- Assign <- FunctionDef -> Assign -> Call -> keyword -> NameConstant', 1)\n",
      "5. ('Name <- Dict <- Assign <- FunctionDef -> Assign -> Call -> Subscript -> Name', 1)\n",
      "6. ('Str <- Dict <- Assign <- FunctionDef -> Assign -> Call -> Subscript -> Name', 1)\n",
      "7. ('Name <- Index <- Subscript <- Return <- If -> Return -> Call -> Name', 1)\n",
      "8. ('Str <- Call <- Expr <- If <- FunctionDef -> Return -> Call -> Call -> Call -> Name', 1)\n",
      "9. ('Name <- Call <- Expr <- If <- FunctionDef -> Return -> Call -> Call -> Call -> Name', 1)\n",
      "10. ('Name <- Call <- UnaryOp <- If <- FunctionDef -> Return -> Call -> Call -> Call -> Name', 1)\n",
      "11. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> BinOp -> BinOp -> Num', 1)\n",
      "12. ('Name <- BinOp <- BinOp <- Assign <- FunctionDef -> Return -> Call -> Call -> Attribute', 1)\n",
      "13. ('Str <- Call <- Expr <- If <- FunctionDef -> Return -> Call -> Call -> Attribute', 1)\n",
      "14. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> Call -> Attribute', 1)\n",
      "15. ('Name <- BinOp <- BinOp <- Assign <- FunctionDef -> Return -> Call -> Call -> Attribute -> Name', 1)\n",
      "16. ('Str <- Call <- Expr <- If <- FunctionDef -> Return -> Call -> Call -> Attribute -> Name', 1)\n",
      "17. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> Call -> Attribute -> Name', 1)\n",
      "18. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> BinOp -> BinOp -> Name', 1)\n",
      "19. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> Call -> Name', 1)\n",
      "20. ('Str <- Call <- Expr <- If <- FunctionDef -> Assign -> BinOp -> Num', 1)\n",
      "\n",
      "Histogram: Code Paths                                                                     \n",
      "Bin         Count  % of names % of vars  %-ile vars                                       \n",
      "1-10       533751     85.233     14.886      14.89                                        \n",
      "10-100      82073     13.106     22.720      37.61                                        \n",
      "100-1000     9283      1.482     27.306      64.91                                        \n",
      "1000-10000   1092      0.174     29.211      94.12                                        \n",
      "10000-100000     30      0.005      5.877     100.00                                      \n",
      "                                                                                          \n",
      "\n",
      "PathsPerPoint.Count     %-ile     \n",
      " 0.        0         0.00000   \n",
      " 1.        22        0.08233   \n",
      " 2.        128       0.56134   \n",
      " 5.        598       2.79919   \n",
      " 10.       1532      8.53230   \n",
      " 20.       2809      19.04423  \n",
      " 50.       4849      37.19033  \n",
      " 100.      3956      51.99461  \n",
      " 500.      8778      84.84395  \n",
      " 1000.     2127      92.80368  \n",
      " 10000.    1892      99.88399  \n",
      " 100000.   28        99.98877  \n",
      " 1000000.  3         100.00000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_all_counts(data):\n",
    "    all_paths = []\n",
    "    all_counts = []\n",
    "    for x in data:\n",
    "        counter = 0\n",
    "        for p in x['path_strings']:\n",
    "            all_paths.append(p)\n",
    "            counter += 1\n",
    "        all_counts.append(counter)\n",
    "    return all_paths, all_counts\n",
    "\n",
    "def _alt_histogram(mc, bins):\n",
    "    tally = [0]\n",
    "    j =0 \n",
    "    for i in mc:\n",
    "        if i[0] > bins[j]:\n",
    "            j+=1\n",
    "            tally.append(0)\n",
    "        tally[-1] += i[1]\n",
    "    tot = sum(tally)\n",
    "    lines = [[\n",
    "            str.ljust(\"{}.\".format(\"PathsPerPoint\"), 10, \" \"),\n",
    "            str.ljust(\"{}  \".format(\"Count\"), 10, \" \"),\n",
    "            str.ljust(\"{}\".format(\"%-ile\"), 10, \" \"),\n",
    "            \"\\n\",\n",
    "        ]]\n",
    "    \n",
    "    c = 0 \n",
    "    for b,t in list(zip(bins, tally)):\n",
    "        c += t\n",
    "        lines.append([\n",
    "            str.ljust(\"{}.\".format(b), 10, \" \"),\n",
    "            str.ljust(\"{}  \".format(t), 10, \" \"),\n",
    "            str.ljust(\"{:.5f}\".format(100*c/tot), 10, \" \"),\n",
    "            \"\\n\",\n",
    "        ])\n",
    "    return \" \".join([\"\".join(l) for l in lines])\n",
    "\n",
    "\n",
    "def most_common_paths(data):\n",
    "    all_paths, all_counts = get_all_counts(data)\n",
    "\n",
    "    codepaths = Counter(all_paths)\n",
    "    mc_codepaths = print_top_and_bottom(codepaths, TOP_N, \"Top Paths\", cols=1)    \n",
    "    path_bins =  [0,1,10,100,1000,10000,100000]\n",
    "    path_histogram = get_histogram(mc_codepaths, path_bins, \"Code Paths\")\n",
    "    print(to_columns(path_histogram , 1, 90))\n",
    "    \n",
    "    codepaths_per_point = Counter(all_counts)\n",
    "    \n",
    "    mc_cpp = sorted(codepaths_per_point.most_common())\n",
    "\n",
    "    bins = [0,1,2,5,10,20,50,100, 500,1000,10000,100000,1000000]\n",
    "    print(_alt_histogram(mc_cpp, bins))\n",
    "\n",
    "most_common_paths(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 Top Paths                   \n",
      "1. ('Name <- keyword <- Call -> keyword', 8520)\n",
      "2. ('Name <- Call -> Name', 8438)  \n",
      "3. ('Name <- keyword <- Call -> keyword -> Name', 8117)\n",
      "4. ('Name <- Call -> Attribute', 3720)\n",
      "5. ('Name <- Call -> Attribute -> Name', 3025)\n",
      "6. ('Name <- keyword <- Call <- Assign <- If -> Assign -> Name', 2873)\n",
      "7. ('Name <- AugAssign <- For <- FunctionDef -> Assign -> List -> List -> Num', 2640)\n",
      "8. ('Name <- keyword <- Call <- Assign <- If -> Try -> Assign -> Call -> Name', 2407)\n",
      "9. ('Name <- Call <- Assign <- Try <- If -> Assign -> Name', 2370)\n",
      "10. ('Name <- Call <- Assign <- Try <- If -> Assign -> Call -> keyword', 2305)\n",
      "11. ('Name <- Call <- Assign <- Try <- If -> Assign -> Call -> keyword -> Name', 2303)\n",
      "12. ('Name <- keyword <- Call -> Name', 2168)\n",
      "13. ('Name <- Assign <- FunctionDef <- ClassDef -> FunctionDef', 2057)\n",
      "14. ('Name <- Call <- Assign <- FunctionDef -> Assign -> Call -> Name', 1976)\n",
      "15. ('Name <- Call <- Assign <- FunctionDef -> Assign -> Name', 1960)\n",
      "16. ('Name <- keyword <- Call <- Assign <- If -> Try -> Assign -> Call -> Attribute', 1874)\n",
      "17. ('Name <- Assign <- FunctionDef -> Assign -> Name', 1801)\n",
      "18. ('Name <- Attribute <- Attribute <- Call <- Expr <- FunctionDef -> Expr -> Call -> Attribute', 1793)\n",
      "19. ('Name <- keyword <- Call <- Assign -> Tuple -> Name', 1743)\n",
      "20. ('Name <- Attribute <- Attribute <- Call <- Expr <- FunctionDef -> Expr -> Call -> Attribute -> Attribute', 1719)\n",
      "BOTTOM 20 Top Paths                \n",
      "1. ('Name <- Attribute <- Subscript <- Subscript <- comprehension -> Name', 1)\n",
      "2. ('Name <- For -> If -> Assign -> ListComp -> comprehension -> Name', 1)\n",
      "3. ('Name <- Call <- Assign <- FunctionDef -> For -> If -> Assign -> ListComp -> comprehension -> Name', 1)\n",
      "4. ('Name <- Attribute <- Subscript <- Subscript <- comprehension <- ListComp -> Subscript -> Index -> Name', 1)\n",
      "5. ('Name <- For -> If -> Assign -> ListComp -> Subscript -> Index -> Name', 1)\n",
      "6. ('Name <- For -> If -> Assign -> ListComp -> comprehension -> Subscript -> Index -> Str', 1)\n",
      "7. ('Name <- Attribute <- Subscript <- Subscript <- comprehension <- ListComp <- Assign -> Subscript -> Index -> Str', 1)\n",
      "8. ('Name <- Attribute <- Subscript <- Subscript <- comprehension <- ListComp <- Assign <- If -> Compare -> Str', 1)\n",
      "9. ('Name <- For -> If -> Assign -> Subscript -> Index -> Subscript -> Index -> Str', 1)\n",
      "10. ('Name <- Attribute <- Subscript <- Subscript <- Index <- Subscript <- Assign -> Subscript -> Index -> Str', 1)\n",
      "11. ('Name <- Attribute <- Subscript <- Subscript <- Index <- Subscript <- Assign <- If -> Compare -> Str', 1)\n",
      "12. ('Name <- comprehension <- ListComp <- Assign <- Try <- FunctionDef -> For -> Expr -> Call -> Attribute', 1)\n",
      "13. ('Name <- For -> Assign -> Subscript -> Index -> Str', 1)\n",
      "14. ('Name <- Call <- Assign <- FunctionDef -> For -> Assign -> Subscript -> Index -> Str', 1)\n",
      "15. ('Name <- Call <- Compare <- If <- FunctionDef -> For -> Assign -> Subscript -> Index -> Str', 1)\n",
      "16. ('Name <- For -> Assign -> Subscript -> Subscript -> Index -> Name', 1)\n",
      "17. ('Name <- For -> If -> Assign -> ListComp -> comprehension -> Subscript -> Subscript -> Index -> Name', 1)\n",
      "18. ('Name <- For -> If -> Assign -> Subscript -> Index -> Subscript -> Subscript -> Index -> Name', 1)\n",
      "19. ('Name <- Call <- Compare <- If <- FunctionDef -> For -> Assign -> Subscript -> Index -> Name', 1)\n",
      "20. ('Name <- Attribute <- Subscript <- Subscript <- comprehension <- ListComp <- Assign <- If <- For -> Name', 1)\n",
      "\n",
      "Histogram: Code Paths                                                                     \n",
      "Bin         Count  % of names % of vars  %-ile vars                                       \n",
      "1-10       149609     90.176     27.617      27.62                                        \n",
      "10-100      14580      8.788     28.653      56.27                                        \n",
      "100-1000     1643      0.990     33.185      89.45                                        \n",
      "1000-10000     75      0.045     10.545     100.00                                        \n",
      "10000-100000      0      0.000      0.000     100.00                                      \n",
      "                                                                                          \n",
      "\n",
      "PathsPerPoint.Count     %-ile     \n",
      " 0.        0         0.00000   \n",
      " 1.        2         0.05274   \n",
      " 2.        10        0.31646   \n",
      " 5.        82        2.47890   \n",
      " 10.       239       8.78165   \n",
      " 20.       361       18.30169  \n",
      " 50.       698       36.70886  \n",
      " 100.      561       51.50316  \n",
      " 500.      1245      84.33544  \n",
      " 1000.     322       92.82700  \n",
      " 10000.    268       99.89451  \n",
      " 100000.   4         100.00000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_common_paths(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Repositories (TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from project.utils.tokenize import get_embed_filenames\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn import manifold, datasets\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from project.data.preprocessed.no_dups_split_X import no_dups_split_X_quickload_data as SPLIT\n",
    "from project.data.preprocessed.no_dups_X import no_dups_X_quickload_data as UNSPLIT\n",
    "DATA = SPLIT()\n",
    "DATA_UNS = UNSPLIT()\n",
    "\n",
    "def load_lookup(dim):\n",
    "    make_null = lambda : np.zeros(dim) \n",
    "    word2vector = defaultdict(make_null)\n",
    "    \n",
    "    with open(get_embed_filenames()[dim], 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word_weights = np.array(values[1:]).astype(np.float32)\n",
    "            word2vector[word] = word_weights \n",
    "    return word2vector\n",
    "    \n",
    "def tsne_transform(X, perplexity, learning_rate):\n",
    "        t0 = time()\n",
    "        tsne = manifold.TSNE(\n",
    "            n_components=2, \n",
    "            init='random',\n",
    "            random_state=0, \n",
    "            learning_rate=learning_rate,\n",
    "            verbose=2,\n",
    "            perplexity=perplexity)\n",
    "        Y = tsne.fit_transform(X)\n",
    "        t1 = time()        \n",
    "        print(\"perplexity=%d in %.2g sec\" % (perplexity, t1 - t0))\n",
    "        return Y \n",
    "\n",
    "def plot_scatter(X, labels):\n",
    "    n_samples = 300\n",
    "    n_components = 2\n",
    "    ax = plt.figure(figsize=(15, 15))\n",
    "\n",
    "\n",
    "    color = labels\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=color, cmap=plt.cm.viridis)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V = load_lookup(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    arr = np.sum(x, axis=0)\n",
    "    norm =  np.linalg.norm(x) \n",
    "    if norm == 0.0:\n",
    "        return  arr\n",
    "    else:\n",
    "        return arr/norm\n",
    "        \n",
    "\n",
    "def add_bag_of_words_desc(data, word2vector):\n",
    "    dim = 200\n",
    "    print(\"Populating\")\n",
    "    for d in data:\n",
    "        word_stack = np.stack([word2vector[t] for t in nltk_tok(d['arg_desc']) if t not in stopwords.words(\"english\")])\n",
    "        d['bag_of_words_vec'] =  np.sum(word_stack, axis=0)\n",
    "    return data\n",
    "\n",
    "def generate_tsne_file(data):\n",
    "    print(\"Writing to File\")\n",
    "    with open('vec.tsv', 'w') as f:\n",
    "        with open('meta.tsv', 'w') as g:\n",
    "            cols = \"\\t\".join(['pkg', 'arg_name', 'name', 'arg_desc'])\n",
    "        \n",
    "            g.write(cols)\n",
    "            g.write(\"\\n\")\n",
    "        \n",
    "            for d in data:\n",
    "                meta_row = \"\\t\".join([d['pkg'], d['arg_name'], d['name'], d['arg_desc']])\n",
    "                g.write(meta_row)\n",
    "                g.write(\"\\n\")\n",
    "                \n",
    "                f.write(\"\\t\".join(str(x) for x in d['bag_of_words_vec']))\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating\n",
      "Populating\n",
      "Populating\n",
      "Writing to File\n"
     ]
    }
   ],
   "source": [
    "TRAIN = add_bag_of_words_desc(DATA_UNS.train, W2V)\n",
    "VALID = add_bag_of_words_desc(DATA_UNS.valid, W2V)\n",
    "TEST  = add_bag_of_words_desc(DATA_UNS.test, W2V)\n",
    "\n",
    "generate_tsne_file(TRAIN + TEST + VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200}\n"
     ]
    }
   ],
   "source": [
    "def gen_tsne_data(data): \n",
    "    x = defaultdict(lambda :len(x))\n",
    "    print(set([len(d['bag_of_words_vec']) for d in data]))\n",
    "    M = np.stack([d['bag_of_words_vec'] for d in data])\n",
    "    L = np.stack([x[d['pkg']] for d in data])\n",
    "    return M, L, x\n",
    "\n",
    "M,L,D = gen_tsne_data(TRAIN + TEST + VALID)\n",
    "E = { v:k for k,v in D.items()}\n",
    "TSNE_results = []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 16 nearest neighbors...\n",
      "[t-SNE] Indexed 34568 samples in 0.415s...\n",
      "[t-SNE] Computed neighbors for 34568 samples in 254.517s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 28000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 29000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 30000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 31000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 32000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 33000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 34000 / 34568\n",
      "[t-SNE] Computed conditional probabilities for sample 34568 / 34568\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] Computed conditional probabilities in 0.637s\n",
      "[t-SNE] Iteration 50: error = 131.0078735, gradient norm = 0.0000032 (50 iterations in 31.632s)\n",
      "[t-SNE] Iteration 100: error = 130.8517151, gradient norm = 0.0012203 (50 iterations in 36.117s)\n",
      "[t-SNE] Iteration 150: error = 118.0049820, gradient norm = 0.0025389 (50 iterations in 31.650s)\n",
      "[t-SNE] Iteration 200: error = 110.7933426, gradient norm = 0.0012934 (50 iterations in 27.286s)\n",
      "[t-SNE] Iteration 250: error = 107.5972214, gradient norm = 0.0009534 (50 iterations in 27.213s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 107.597221\n",
      "[t-SNE] Iteration 300: error = 6.1744590, gradient norm = 0.0019065 (50 iterations in 27.401s)\n",
      "[t-SNE] Iteration 350: error = 5.7050252, gradient norm = 0.0013337 (50 iterations in 25.906s)\n",
      "[t-SNE] Iteration 400: error = 5.2828474, gradient norm = 0.0010002 (50 iterations in 24.234s)\n",
      "[t-SNE] Iteration 450: error = 4.9305949, gradient norm = 0.0007887 (50 iterations in 23.307s)\n",
      "[t-SNE] Iteration 500: error = 4.6408367, gradient norm = 0.0006468 (50 iterations in 24.700s)\n",
      "[t-SNE] Iteration 550: error = 4.3920836, gradient norm = 0.0005458 (50 iterations in 26.063s)\n",
      "[t-SNE] Iteration 600: error = 4.1781602, gradient norm = 0.0004708 (50 iterations in 25.705s)\n",
      "[t-SNE] Iteration 650: error = 3.9927664, gradient norm = 0.0004132 (50 iterations in 26.002s)\n",
      "[t-SNE] Iteration 700: error = 3.8300319, gradient norm = 0.0003674 (50 iterations in 25.768s)\n",
      "[t-SNE] Iteration 750: error = 3.6813087, gradient norm = 0.0003300 (50 iterations in 25.754s)\n",
      "[t-SNE] Iteration 800: error = 3.5487533, gradient norm = 0.0002993 (50 iterations in 25.639s)\n",
      "[t-SNE] Iteration 850: error = 3.4298496, gradient norm = 0.0002734 (50 iterations in 25.014s)\n",
      "[t-SNE] Iteration 900: error = 3.3203337, gradient norm = 0.0002514 (50 iterations in 23.224s)\n",
      "[t-SNE] Iteration 950: error = 3.2199376, gradient norm = 0.0002324 (50 iterations in 23.235s)\n",
      "[t-SNE] Iteration 1000: error = 3.1258216, gradient norm = 0.0002159 (50 iterations in 23.211s)\n",
      "[t-SNE] Error after 1000 iterations: 3.125822\n",
      "perplexity=5 in 7.8e+02 sec\n"
     ]
    }
   ],
   "source": [
    "l = 50\n",
    "p = 5\n",
    "Y = tsne_transform(M, perplexity=p, learning_rate=l)\n",
    "TSNE_results.append((Y,p,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L2 = [E[x] for x in L] \n",
    "L3  = ['blue' if x not in {'tensorflow', 'sklearn', 'pandas', 'numpy', 'scipy', 'theano','torch','nltk'} else 'red' for x in L2]\n",
    "plot_scatter(Y, L3)\n",
    "print(set(L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 50\n",
    "p = 30\n",
    "Y2 = tsne_transform(M, perplexity=p, learning_rate=l)\n",
    "TSNE_results.append((Y2,p,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L2 = [E[x] for x in L] \n",
    "L3  = ['blue' if x not in {'tensorflow', 'sklearn', 'pandas', 'numpy', 'scipy', 'theano','torch','nltk'} else 'red' for x in L2]\n",
    "plot_scatter(Y2, L3)\n",
    "print(set(L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "p = 30\n",
    "Y3 = tsne_transform(M, perplexity=p, learning_rate=l)\n",
    "TSNE_results.append((Y3,p,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L2 = [E[x] for x in L] \n",
    "L3  = ['blue' if x not in {'tensorflow', 'sklearn', 'pandas', 'numpy', 'scipy', 'theano','torch','nltk'} else 'red' for x in L2]\n",
    "plot_scatter(Y3, L3)\n",
    "print(set(L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 50\n",
    "p = 50\n",
    "Y4 = tsne_transform(M, perplexity=p, learning_rate=l)\n",
    "TSNE_results.append((Y4,p,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L2 = [E[x] for x in L] \n",
    "L3  = ['blue' if x not in {'tensorflow', 'sklearn', 'pandas', 'numpy', 'scipy', 'theano','torch','nltk'} else 'red' for x in L2]\n",
    "plot_scatter(Y4, L3)\n",
    "print(set(L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
